{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17466d3",
   "metadata": {},
   "source": [
    "#### Because of memory constraint, wasn't able to perform xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e91bd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)\n",
    "dotenv_path = os.path.join(root_dir, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0e3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87877b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = os.path.join(root_dir, \"data\", \"train_split.parquet\")\n",
    "valid = os.path.join(root_dir, \"data\", \"valid_split.parquet\")\n",
    "\n",
    "train_df = pl.read_parquet(train)\n",
    "valid_df = pl.read_parquet(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60980904",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"selected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13814f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to exclude\n",
    "exclude_cols = {\"ranker_id\", \"row_id\", TARGET_COL}\n",
    "\n",
    "# Determine feature columns from train_df\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48723411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper: build DMatrix from parquet\n",
    "# -----------------------------\n",
    "def build_dmatrix(df, target_col):\n",
    "    # Check target\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"{target_col} not in {parquet_path}\")\n",
    "\n",
    "    # Cast features to float32 to save memory\n",
    "    exclude_cols = {\"ranker_id\", \"row_id\", target_col}\n",
    "    feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "    df = df.with_columns([pl.col(c).cast(pl.Float32) for c in feature_cols])\n",
    "\n",
    "    # Extract numpy arrays\n",
    "    X = df.select(feature_cols).to_numpy()\n",
    "    y = df[target_col].to_numpy()\n",
    "\n",
    "    # Group sizes (count rows per ranker_id)\n",
    "    group_sizes = (\n",
    "        df.group_by(\"ranker_id\")\n",
    "          .len()\n",
    "          .sort(\"ranker_id\")[\"len\"]\n",
    "          .to_list()\n",
    "    )\n",
    "\n",
    "    dmat = xgb.DMatrix(X, label=y)\n",
    "    dmat.set_group(group_sizes)\n",
    "    print(f\"[INFO] Built DMatrix with {X.shape[0]} rows and {X.shape[1]} features.\")\n",
    "    return dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698be13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train/valid matrices & Free memory\n",
    "dtrain = build_dmatrix(train_df, TARGET_COL)\n",
    "dvalid = build_dmatrix(valid_df, TARGET_COL)\n",
    "\n",
    "del train_df\n",
    "del valid_df\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb39fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"rank:pairwise\",   # or rank:ndcg\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"eval_metric\": \"ndcg@3\"\n",
    "}\n",
    "\n",
    "print(\"[INFO] Training...\")\n",
    "evals_result = {}\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    evals_result=evals_result,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=5\n",
    ")\n",
    "\n",
    "print(f\"[RESULT] Best iteration: {bst.best_iteration}\")\n",
    "print(f\"[RESULT] Best validation score: {bst.best_score}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Save model\n",
    "# -----------------------------\n",
    "model_path = os.path.join(root_dir, \"rank_xgb_model.json\")\n",
    "bst.save_model(model_path)\n",
    "print(f\"[INFO] Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e35c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
