{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed74b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)\n",
    "dotenv_path = os.path.join(root_dir, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1573e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840e3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet(os.path.join(root_dir, \"data\", \"v1\", \"train.parquet\"))\n",
    "train_target = pl.read_parquet(os.path.join(root_dir, \"data\", \"v1\", \"train_target.parquet\"))\n",
    "test_df = pl.read_parquet(os.path.join(root_dir, \"data\", \"v1\", \"test.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d4e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_seg = train_df.select([\n",
    "    \"row_id\",\n",
    "    \"ranker_id\",\n",
    "    \n",
    "    \"go_seg_number\",\n",
    "    \"go_bag_allow_0\",\n",
    "    \"go_travel_distance\",\n",
    "    \"go_total_flight_time\",\n",
    "    \"go_exchange_wait\",\n",
    "    \"go_airline_is_lcc_0\",\n",
    "    \"go_international\",\n",
    "    \n",
    "    \"rtn_seg_number\",\n",
    "    \"rtn_bag_allow_0\",\n",
    "    \"rtn_travel_distance\",\n",
    "    \"rtn_total_flight_time\",\n",
    "    \"rtn_exchange_wait\",\n",
    "    \"rtn_airline_is_lcc_0\", # Major carrier?\n",
    "    \n",
    "    \"is_vip\",\n",
    "    \"is_access_tp\",\n",
    "    \"is_access_3d\",\n",
    "    \"has_corporate_tariff\",\n",
    "    \"frequent_flyer_count\",\n",
    "    \"any_segment_in_ff\",\n",
    "\n",
    "    \"price_rank\",\n",
    "    \"price_delta\",\n",
    "    \"departure_rank\",\n",
    "    \"is_preferred_airline\",\n",
    "    \"lead_time_days\",\n",
    "    \"departure_month\",\n",
    "])\n",
    "\n",
    "test_df_seg = test_df.select([\n",
    "    \"row_id\",\n",
    "    \"ranker_id\",\n",
    "    \n",
    "    \"go_seg_number\",\n",
    "    \"go_bag_allow_0\",\n",
    "    \"go_travel_distance\",\n",
    "    \"go_total_flight_time\",\n",
    "    \"go_exchange_wait\",\n",
    "    \"go_airline_is_lcc_0\",\n",
    "    \"go_international\",\n",
    "    \n",
    "    \"rtn_seg_number\",\n",
    "    \"rtn_bag_allow_0\",\n",
    "    \"rtn_travel_distance\",\n",
    "    \"rtn_total_flight_time\",\n",
    "    \"rtn_exchange_wait\",\n",
    "    \"rtn_airline_is_lcc_0\", # Major carrier?\n",
    "    \n",
    "    \"is_vip\",\n",
    "    \"is_access_tp\",\n",
    "    \"is_access_3d\",\n",
    "    \"has_corporate_tariff\",\n",
    "    \"frequent_flyer_count\",\n",
    "    \"any_segment_in_ff\",\n",
    "\n",
    "    \"price_rank\",\n",
    "    \"price_delta\",\n",
    "    \"departure_rank\",\n",
    "    \"is_preferred_airline\",\n",
    "    \"lead_time_days\",\n",
    "    \"departure_month\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8c302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_ids = train_df_seg.select(\"ranker_id\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207e19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_id_train, ranker_id_valid = train_test_split(\n",
    "    ranker_ids.to_numpy().reshape(-1),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7655b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = train_df_seg[\"ranker_id\"].is_in(ranker_id_train)\n",
    "valid_mask = train_df_seg[\"ranker_id\"].is_in(ranker_id_valid)\n",
    "\n",
    "train_idx = train_mask.to_numpy().nonzero()[0]\n",
    "valid_idx = valid_mask.to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c941d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_df_seg[train_idx], train_df_seg[valid_idx]\n",
    "y_train, y_val = train_target[train_idx], train_target[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b235496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (14575710, 27), y_train: (14575710, 2)\n",
      "X_val: (3569662, 27), y_val: (3569662, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2792c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.drop(\"ranker_id\").drop(\"row_id\").to_numpy()\n",
    "y_train_np = y_train['selected'].to_numpy()\n",
    "\n",
    "X_val_np = X_val.drop(\"ranker_id\").drop(\"row_id\").to_numpy()\n",
    "y_val_np = y_val['selected'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e588f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = test_df_seg.drop(\"ranker_id\").drop(\"row_id\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b21ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_sizes = X_train.group_by(\"ranker_id\").len().sort(\"ranker_id\")[\"len\"].to_numpy()\n",
    "val_group_sizes = X_val.group_by(\"ranker_id\").len().sort(\"ranker_id\")[\"len\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af7db56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_np, label=y_train_np)\n",
    "dtrain.set_group(train_group_sizes)\n",
    "\n",
    "dval = xgb.DMatrix(X_val_np, label=y_val_np)\n",
    "dval.set_group(val_group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be0ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649ee53",
   "metadata": {},
   "source": [
    "#### Optuna - hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2dad541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the hyper parameter using optuna\n",
    "def groupwise_ndcg(y_true, y_pred, group_ids, k=3):\n",
    "    df = pd.DataFrame({\n",
    "        \"group\": group_ids,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "\n",
    "    grouped = df.groupby(\"group\")\n",
    "\n",
    "    scores = grouped.apply(\n",
    "        lambda g: ndcg_score(\n",
    "            [g[\"y_true\"].values],\n",
    "            [g[\"y_pred\"].values],\n",
    "            k=k\n",
    "        ) if len(g) >= 2 else None\n",
    "    ).dropna()\n",
    "\n",
    "    return scores.mean() if not scores.empty else 0.0\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"rank:pairwise\",\n",
    "        \"eval_metric\": \"ndcg@3\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 14),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.01, 10, log=True),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.01, 10, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.01, 5, log=True),\n",
    "        \"verbosity\": 1,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    model = xgb.train(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dval, \"eval\")],\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dval)\n",
    "    score = groupwise_ndcg(y_val_np, preds, X_val['ranker_id'].to_numpy(), k=3)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2864692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-29 13:03:29,482] A new study created in RDB with name: xgb_20250729_130329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-ndcg@3:0.78627\n",
      "[1]\teval-ndcg@3:0.79452\n",
      "[2]\teval-ndcg@3:0.79782\n",
      "[3]\teval-ndcg@3:0.79914\n",
      "[4]\teval-ndcg@3:0.80027\n",
      "[5]\teval-ndcg@3:0.80080\n",
      "[6]\teval-ndcg@3:0.80108\n",
      "[7]\teval-ndcg@3:0.80141\n",
      "[8]\teval-ndcg@3:0.80218\n",
      "[9]\teval-ndcg@3:0.80271\n",
      "[10]\teval-ndcg@3:0.80300\n",
      "[11]\teval-ndcg@3:0.80290\n",
      "[12]\teval-ndcg@3:0.80313\n",
      "[13]\teval-ndcg@3:0.80318\n",
      "[14]\teval-ndcg@3:0.80315\n",
      "[15]\teval-ndcg@3:0.80343\n",
      "[16]\teval-ndcg@3:0.80401\n",
      "[17]\teval-ndcg@3:0.80389\n",
      "[18]\teval-ndcg@3:0.80438\n",
      "[19]\teval-ndcg@3:0.80478\n",
      "[20]\teval-ndcg@3:0.80470\n",
      "[21]\teval-ndcg@3:0.80430\n",
      "[22]\teval-ndcg@3:0.80509\n",
      "[23]\teval-ndcg@3:0.80550\n",
      "[24]\teval-ndcg@3:0.80531\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    storage=f\"sqlite:///{os.path.join(root_dir, 'db.sqlite3')}\", \n",
    "    study_name=f'xgb_{datetime.now().strftime('%Y%m%d_%H%M%S')}'\n",
    ")\n",
    "study.optimize(objective, n_trials=50)  # ⏱️ takes time\n",
    "\n",
    "print(\"[BEST PARAMS]\")\n",
    "print(study.best_params)\n",
    "print(\"Best NDCG@3:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"max_depth\": 14,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"subsample\": 0.8842234913702768,\n",
    "    \"colsample_bytree\": 0.45840689146263086,\n",
    "    \"gamma\": 3.3084297630544888,\n",
    "    \"lambda\": 6.952586917313028,\n",
    "    \"alpha\": 0.6395254133055179,\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    # 'device': 'cuda'\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=watchlist,\n",
    "    # early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance = model.get_score(importance_type='gain')\n",
    "xgb_importance_df = pl.DataFrame(\n",
    "    [{'feature': k, 'importance': v} for k, v in xgb_importance.items()]\n",
    ").sort('importance', descending=bool(1))\n",
    "print(xgb_importance_df.to_pandas().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e58a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pl.read_parquet(os.path.join(root_dir, \"kaggle\", \"test.parquet\"))\n",
    "original = (\n",
    "    original\n",
    "    .select([\"Id\", \"ranker_id\"])\n",
    "    .with_columns(\n",
    "        pl.Series(\"score\", pred_scores)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('score')\n",
    "        .rank(method='ordinal', descending=True)\n",
    "        .over('ranker_id')\n",
    "        .alias('selected')\n",
    "    )\n",
    "    .select([\"Id\", \"ranker_id\", \"selected\"])\n",
    "    .with_columns(\n",
    "        pl.col(\"Id\").cast(pl.Int64), \n",
    "        pl.col(\"selected\").cast(pl.Int64)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "original.write_csv(os.path.join(root_dir, \"submission\", f\"submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7ee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
