{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2cf20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)\n",
    "dotenv_path = os.path.join(root_dir, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fd86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_insert import ParquetRankDataset\n",
    "from src.model import RankerNN\n",
    "from src.metric import pairwise_loss\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3b879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZATION = os.path.join(root_dir, \"data\", \"train\", \"train_split_0.parquet\")\n",
    "test_file_paths = [os.path.join(root_dir, \"data\", \"test\", \"test.parquet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17affa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "d = pl.scan_parquet(test_file_paths[0])\n",
    "d2 = pl.scan_parquet(NORMALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goonzard/Developer/data-science-09-kaggle-airplane/src/data_insert.py:29: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  self.feature_cols: list[str] = [c for c in first_schema.columns if c not in self.exclude_feature_cols]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalization stats loaded from /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/train/train_split_0.parquet\n",
      "[INFO] Example mean/std: [('emb_0', 0.044884927570819855), ('emb_1', -0.026697352528572083), ('emb_2', -0.10396946221590042), ('emb_3', 0.04172823578119278), ('emb_4', -0.01801719330251217)]\n"
     ]
    }
   ],
   "source": [
    "EXCLUDED_COLS = ['row_id', 'ranker_id', 'selected']\n",
    "\n",
    "LABEL_COL = 'dummy_selected'\n",
    "GROUP_COL = 'ranker_id'\n",
    "\n",
    "test_dataset_stream = ParquetRankDataset(\n",
    "    parquet_paths=test_file_paths,\n",
    "    exclude_feature_cols=EXCLUDED_COLS,\n",
    "    label_col=LABEL_COL,\n",
    "    group_col=GROUP_COL,\n",
    "    max_rows=4096,\n",
    "    normalization_parquet=NORMALIZATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYERS = [512, 256, 128]\n",
    "HIDDEN_LAYERS_STR = \"_\".join(map(str, HIDDEN_LAYERS))\n",
    "\n",
    "DROP_RATE = 0.2\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_DATE = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "VAL_INTERVAL = 500\n",
    "PATIENCE = 5\n",
    "BEST_VAL_LOSS = float(\"inf\")\n",
    "NO_IMPROVE_COUNT = 0\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "SAVED_MODEL_NAME = f\"best_model_2_512_256_128_0.2_0.001.pt\"\n",
    "SAVED_MODEL_FILE = os.path.join(root_dir, \"models\", SAVED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4129fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankerNN(\n",
    "    n_features=test_dataset_stream.feature_len, \n",
    "    hidden_layers=HIDDEN_LAYERS, \n",
    "    dropout=DROP_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcec4b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RankerNN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=418, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): GELU(approximate='none')\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): GELU(approximate='none')\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset_stream, batch_size=None, shuffle=False)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon GPU via Metal\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the best model so far\n",
    "state_dict = torch.load(SAVED_MODEL_FILE, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "all_scores = []\n",
    "all_groups = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, _, G in test_loader:  # labels are dummy\n",
    "        X = X.to(device)\n",
    "        scores = model(X)  # (batch_size, 1)\n",
    "        all_scores.append(scores.cpu())\n",
    "        all_groups.append(G)\n",
    "\n",
    "all_scores = torch.cat(all_scores).squeeze()\n",
    "all_groups = torch.cat(all_groups)\n",
    "\n",
    "print(\"[INFO] Inference complete:\", all_scores.shape, all_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-PROCESS TO SUBMISSION\n",
    "df_pred = (\n",
    "    pl.DataFrame({\n",
    "        \"score\": all_scores.numpy()\n",
    "    })\n",
    "    .with_row_index(\"id\")\n",
    ")\n",
    "\n",
    "# Replace `ranker_id` with original column\n",
    "original_ranker_id = (\n",
    "    pl.read_parquet(test_file_paths[0])\n",
    "    .select([\"ranker_id\"])\n",
    "    .with_row_index(\"id\")\n",
    ")\n",
    "\n",
    "# Replace `Id` with the original columns\n",
    "original = pl.read_parquet(os.path.join(root_dir, \"kaggle\", \"test.parquet\"))\n",
    "original = original.select(\"Id\").with_row_index(\"id\")\n",
    "\n",
    "df_pred = (\n",
    "    df_pred\n",
    "    .join(original_ranker_id, on=\"id\")\n",
    "    .join(original, on=\"id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e0c04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = df_pred.with_columns(\n",
    "    pl.col(\"score\")\n",
    "    .rank(method='ordinal', descending=True)\n",
    "    .over(\"ranker_id\")\n",
    "    .alias(\"selected\")\n",
    ").select([\"Id\", \"ranker_id\", \"selected\"])\n",
    "\n",
    "final_result = final_result.with_columns(\n",
    "    pl.col(\"Id\").cast(pl.Int64),\n",
    "    pl.col(\"selected\").cast(pl.Int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a443e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "(\n",
    "    final_result\n",
    "    .write_csv(os.path.join(root_dir, \"submission\", f\"submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f365593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No duplicate ranks per ranker_id\n"
     ]
    }
   ],
   "source": [
    "check = (\n",
    "    final_result\n",
    "    .group_by(\"ranker_id\")\n",
    "    .agg([\n",
    "        pl.len().alias(\"total_rows\"),\n",
    "        pl.col(\"selected\").n_unique().alias(\"unique_ranks\")\n",
    "    ])\n",
    "    .filter(pl.col(\"total_rows\") != pl.col(\"unique_ranks\"))\n",
    ")\n",
    "\n",
    "if check.height == 0:\n",
    "    print(\"✅ No duplicate ranks per ranker_id\")\n",
    "else:\n",
    "    print(\"❌ Duplicate ranks found!\")\n",
    "    print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77761813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
