{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8fed41",
   "metadata": {},
   "source": [
    "### IMPORTANT\n",
    "\n",
    "OpenAI's API takes too long time to complete the embedding of ontology layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4526a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)\n",
    "dotenv_path = os.path.join(root_dir, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c7ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goonzard/Developer/data-science-09-kaggle-airplane/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741f9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATH = os.path.join(root_dir, \"data\", \"processed_flight_features_train.parquet\")\n",
    "OUTPUT_DIR = os.path.join(root_dir, \"data\", \"embedded_flight_feature_lite_train\")\n",
    "\n",
    "PARQUET_OUT_DIR = os.path.join(root_dir, \"data\", \"embedded_flight_feature_lite_parquet_train\")\n",
    "\n",
    "COL_NAME = \"flight_text\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516760fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total rows: 18145372\n"
     ]
    }
   ],
   "source": [
    "scan = pl.scan_parquet(PARQUET_PATH).select([COL_NAME]).with_row_index(\"row_id\")\n",
    "row_count = scan.select(pl.len()).collect(engine=\"streaming\")[0, 0]\n",
    "print(f\"[INFO] Total rows: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581e46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 17600384  # Edit here for resuming\n",
    "chunk_idx = 137502  # Edit here for resuming\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "while start < row_count:\n",
    "    end = min(start + BATCH_SIZE, row_count)\n",
    "    print(f\"[INFO] Processing rows {start} to {end} of {row_count}\")\n",
    "\n",
    "    # Collect this chunk\n",
    "    df_chunk = (\n",
    "        pl.scan_parquet(PARQUET_PATH)\n",
    "        .select([COL_NAME])\n",
    "        .with_row_index(\"row_id\")\n",
    "        .filter((pl.col(\"row_id\") >= start) & (pl.col(\"row_id\") < end))\n",
    "        .collect(engine=\"streaming\")\n",
    "    )\n",
    "\n",
    "    texts = df_chunk[COL_NAME].to_list()\n",
    "    row_ids = df_chunk[\"row_id\"].to_list()\n",
    "\n",
    "    # Encode in smaller batches\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        subtexts = texts[i:i+BATCH_SIZE]\n",
    "        emb = model.encode(\n",
    "            subtexts,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)  # shape: (chunk_size, 384)\n",
    "    # Save embeddings and row_ids\n",
    "    out_file = os.path.join(OUTPUT_DIR, f\"embeddings_part{chunk_idx:05d}.npz\")\n",
    "    np.savez_compressed(out_file, row_ids=np.array(row_ids), embeddings=all_embeddings)\n",
    "    print(f\"[INFO] Saved {len(row_ids)} embeddings to {out_file}\")\n",
    "\n",
    "    # Next chunk\n",
    "    start = end\n",
    "    chunk_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7a2b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 141761 chunk files\n",
      "[INFO] Processing split 1/15: files 0 to 9450 (9451 files)\n",
      "[INFO] Saved split 1 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part00.parquet\n",
      "[INFO] Processing split 2/15: files 9451 to 18901 (9451 files)\n",
      "[INFO] Saved split 2 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part01.parquet\n",
      "[INFO] Processing split 3/15: files 18902 to 28352 (9451 files)\n",
      "[INFO] Saved split 3 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part02.parquet\n",
      "[INFO] Processing split 4/15: files 28353 to 37803 (9451 files)\n",
      "[INFO] Saved split 4 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part03.parquet\n",
      "[INFO] Processing split 5/15: files 37804 to 47254 (9451 files)\n",
      "[INFO] Saved split 5 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part04.parquet\n",
      "[INFO] Processing split 6/15: files 47255 to 56705 (9451 files)\n",
      "[INFO] Saved split 6 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part05.parquet\n",
      "[INFO] Processing split 7/15: files 56706 to 66156 (9451 files)\n",
      "[INFO] Saved split 7 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part06.parquet\n",
      "[INFO] Processing split 8/15: files 66157 to 75607 (9451 files)\n",
      "[INFO] Saved split 8 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part07.parquet\n",
      "[INFO] Processing split 9/15: files 75608 to 85058 (9451 files)\n",
      "[INFO] Saved split 9 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part08.parquet\n",
      "[INFO] Processing split 10/15: files 85059 to 94509 (9451 files)\n",
      "[INFO] Saved split 10 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part09.parquet\n",
      "[INFO] Processing split 11/15: files 94510 to 103960 (9451 files)\n",
      "[INFO] Saved split 11 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part10.parquet\n",
      "[INFO] Processing split 12/15: files 103961 to 113411 (9451 files)\n",
      "[INFO] Saved split 12 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part11.parquet\n",
      "[INFO] Processing split 13/15: files 113412 to 122862 (9451 files)\n",
      "[INFO] Saved split 13 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part12.parquet\n",
      "[INFO] Processing split 14/15: files 122863 to 132313 (9451 files)\n",
      "[INFO] Saved split 14 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part13.parquet\n",
      "[INFO] Processing split 15/15: files 132314 to 141760 (9447 files)\n",
      "[INFO] Saved split 15 -> /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part14.parquet\n"
     ]
    }
   ],
   "source": [
    "# find all npz files\n",
    "NUM_OUTPUTS = 15\n",
    "\n",
    "npz_files = sorted(Path(OUTPUT_DIR).glob(\"embeddings_part*.npz\"))\n",
    "total_files = len(npz_files)\n",
    "print(f\"[INFO] Found {total_files} chunk files\")\n",
    "\n",
    "# how many files per parquet group (ceil)\n",
    "files_per_split = math.ceil(total_files / NUM_OUTPUTS)\n",
    "\n",
    "for split_idx in range(NUM_OUTPUTS):\n",
    "    start = split_idx * files_per_split\n",
    "    end = min((split_idx + 1) * files_per_split, total_files)\n",
    "    split_files = npz_files[start:end]\n",
    "\n",
    "    if not split_files:  # no files left\n",
    "        break\n",
    "\n",
    "    print(f\"[INFO] Processing split {split_idx+1}/{NUM_OUTPUTS}: files {start} to {end-1} ({len(split_files)} files)\")\n",
    "\n",
    "    all_tables = []\n",
    "\n",
    "    for f in split_files:\n",
    "        data = np.load(f)\n",
    "        row_ids = data[\"row_ids\"]\n",
    "        embeddings = data[\"embeddings\"]\n",
    "        n_samples, dim = embeddings.shape\n",
    "\n",
    "        embed_cols = {f\"emb_{i}\": embeddings[:, i] for i in range(dim)}\n",
    "\n",
    "        df = pl.DataFrame({\n",
    "            \"row_id\": row_ids,\n",
    "            **embed_cols\n",
    "        })\n",
    "        all_tables.append(df)\n",
    "\n",
    "    merged_df = pl.concat(all_tables, how=\"vertical\")\n",
    "    merged_df = merged_df.sort(\"row_id\")\n",
    "\n",
    "    out_path = os.path.join(PARQUET_OUT_DIR, f\"merged_part{split_idx:02d}.parquet\")\n",
    "    merged_df.write_parquet(out_path)\n",
    "    print(f\"[INFO] Saved split {split_idx+1} -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e471e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 15 parquet files\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part00.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part01.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part02.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part03.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part04.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part05.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part06.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part07.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part08.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part09.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part10.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part11.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part12.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part13.parquet\n",
      "[INFO] Loading /Users/goonzard/Developer/data-science-09-kaggle-airplane/data/embedded_flight_feature_lite_parquet_train/merged_part14.parquet\n",
      "[INFO] Final merged shape: (18145372, 385)\n"
     ]
    }
   ],
   "source": [
    "# Collect all parquet files (adjust pattern if needed)\n",
    "parquet_files = sorted(Path(PARQUET_OUT_DIR).glob(\"merged_part*.parquet\"))\n",
    "print(f\"[INFO] Found {len(parquet_files)} parquet files\")\n",
    "\n",
    "all_tables = []\n",
    "\n",
    "for f in parquet_files:\n",
    "    print(f\"[INFO] Loading {f}\")\n",
    "    df = pl.read_parquet(f)\n",
    "    all_tables.append(df)\n",
    "\n",
    "# Merge them into one DataFrame\n",
    "merged_df = pl.concat(all_tables, how=\"vertical\")\n",
    "\n",
    "# (Optional) sort by row_id if needed\n",
    "merged_df = merged_df.sort(\"row_id\")\n",
    "\n",
    "print(f\"[INFO] Final merged shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e19f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(root_dir, \"data\", \"embed_flight_feature_train.parquet\")\n",
    "merged_df.write_parquet(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
