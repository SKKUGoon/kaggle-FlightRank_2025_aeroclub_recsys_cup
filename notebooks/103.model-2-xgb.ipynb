{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed74b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)\n",
    "dotenv_path = os.path.join(root_dir, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1573e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goonzard/Developer/data-science-09-kaggle-airplane/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840e3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet(os.path.join(root_dir, \"data\", \"v2\", \"train.parquet\"))\n",
    "train_target = pl.read_parquet(os.path.join(root_dir, \"data\", \"v2\", \"train_target.parquet\"))\n",
    "test_df = pl.read_parquet(os.path.join(root_dir, \"data\", \"v2\", \"test.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d4e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_seg = train_df.select([\n",
    "    \"row_id\",\n",
    "    \"ranker_id\",\n",
    "    \n",
    "    \"go_seg_number\",\n",
    "    \"go_bag_allow_0\",\n",
    "    \"go_travel_distance\",\n",
    "    \"go_total_flight_time\",\n",
    "    \"go_exchange_wait\",\n",
    "    \"go_airline_is_lcc_0\",\n",
    "    \"go_international\",\n",
    "    \n",
    "    \"rtn_seg_number\",\n",
    "    \"rtn_bag_allow_0\",\n",
    "    \"rtn_travel_distance\",\n",
    "    \"rtn_total_flight_time\",\n",
    "    \"rtn_exchange_wait\",\n",
    "    \"rtn_airline_is_lcc_0\", # Major carrier?\n",
    "    \n",
    "    \"is_vip\",\n",
    "    \"is_access_tp\",\n",
    "    \"is_access_3d\",\n",
    "    \"has_corporate_tariff\",\n",
    "    \"frequent_flyer_count\",\n",
    "    \"any_segment_in_ff\",\n",
    "\n",
    "    \"price_rank\",\n",
    "    \"price_delta\",\n",
    "    \"departure_rank\",\n",
    "    \"is_preferred_airline\",\n",
    "    \"lead_time_days\",\n",
    "    \"departure_month\",\n",
    "])\n",
    "\n",
    "test_df_seg = test_df.select([\n",
    "    \"row_id\",\n",
    "    \"ranker_id\",\n",
    "    \n",
    "    \"go_seg_number\",\n",
    "    \"go_bag_allow_0\",\n",
    "    \"go_travel_distance\",\n",
    "    \"go_total_flight_time\",\n",
    "    \"go_exchange_wait\",\n",
    "    \"go_airline_is_lcc_0\",\n",
    "    \"go_international\",\n",
    "    \n",
    "    \"rtn_seg_number\",\n",
    "    \"rtn_bag_allow_0\",\n",
    "    \"rtn_travel_distance\",\n",
    "    \"rtn_total_flight_time\",\n",
    "    \"rtn_exchange_wait\",\n",
    "    \"rtn_airline_is_lcc_0\", # Major carrier?\n",
    "    \n",
    "    \"is_vip\",\n",
    "    \"is_access_tp\",\n",
    "    \"is_access_3d\",\n",
    "    \"has_corporate_tariff\",\n",
    "    \"frequent_flyer_count\",\n",
    "    \"any_segment_in_ff\",\n",
    "\n",
    "    \"price_rank\",\n",
    "    \"price_delta\",\n",
    "    \"departure_rank\",\n",
    "    \"is_preferred_airline\",\n",
    "    \"lead_time_days\",\n",
    "    \"departure_month\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8c302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_ids = train_df_seg.select(\"ranker_id\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe885d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 105539 ranker_ids\n"
     ]
    }
   ],
   "source": [
    "print(f\"I have {len(ranker_ids)} ranker_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207e19a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 68600\n",
      "Valid size: 36939\n"
     ]
    }
   ],
   "source": [
    "ranker_id_train, ranker_id_valid = train_test_split(\n",
    "    ranker_ids.to_numpy().reshape(-1),\n",
    "    test_size=0.35,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(ranker_id_train))\n",
    "print(\"Valid size:\", len(ranker_id_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7655b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = train_df_seg[\"ranker_id\"].is_in(ranker_id_train)\n",
    "valid_mask = train_df_seg[\"ranker_id\"].is_in(ranker_id_valid)\n",
    "\n",
    "train_idx = train_mask.to_numpy().nonzero()[0]\n",
    "valid_idx = valid_mask.to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c941d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_df_seg[train_idx], train_df_seg[valid_idx]\n",
    "y_train, y_val = train_target[train_idx], train_target[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b235496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (11844170, 27), y_train: (11844170, 2)\n",
      "X_val: (6301202, 27), y_val: (6301202, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2792c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.drop(\"ranker_id\").drop(\"row_id\").to_numpy()\n",
    "y_train_np = y_train['selected'].to_numpy()\n",
    "\n",
    "X_val_np = X_val.drop(\"ranker_id\").drop(\"row_id\").to_numpy()\n",
    "y_val_np = y_val['selected'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e588f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = test_df_seg.drop(\"ranker_id\").drop(\"row_id\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b21ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_sizes = X_train.group_by(\"ranker_id\").len().sort(\"ranker_id\")[\"len\"].to_numpy()\n",
    "val_group_sizes = X_val.group_by(\"ranker_id\").len().sort(\"ranker_id\")[\"len\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af7db56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_np, label=y_train_np)\n",
    "dtrain.set_group(train_group_sizes)\n",
    "\n",
    "dval = xgb.DMatrix(X_val_np, label=y_val_np)\n",
    "dval.set_group(val_group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be0ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649ee53",
   "metadata": {},
   "source": [
    "#### Optuna - hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2dad541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the hyper parameter using optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"rank:pairwise\",\n",
    "        \"eval_metric\": \"ndcg@3\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 12, 14),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 10, 100),  # Increase to prevent overfit. Prevent splits on tiny groups\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9), # Force diversity. Force generalizable splits\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.8), \n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-3, 1.0, log=True),  # Avoid excessive meorization.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.1, 10, log=True),  # Avoid excessive meorization.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.01, 1.0, log=True),  # Avoid excessive meorization.\n",
    "        \"verbosity\": 1,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    # Connects XGBoost's training process to Optuna's pruning mechanisms\n",
    "    # During train, XGBoost logs the eval-ndcg@3 score\n",
    "    # The callback watches that score and calls `trial.report(step-iteration)`\n",
    "    prune_callback = optuna.integration.XGBoostPruningCallback(trial, \"eval-ndcg@3\")\n",
    "\n",
    "    model = xgb.train(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain, \"train\"), (dval, \"eval\")],\n",
    "        callbacks=[prune_callback],\n",
    "        early_stopping_rounds=100,\n",
    "    )\n",
    "\n",
    "    score = model.best_score  # `best_score` is only defined when early stopping is used.\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2864692",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    storage=f\"sqlite:///{os.path.join(root_dir, 'db.sqlite3')}\", \n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "    study_name=f'xgb_{datetime.now().strftime('%Y%m%d_%H%M%S')}'\n",
    ")\n",
    "study.optimize(objective, n_trials=50)  # ⏱️ takes time\n",
    "\n",
    "print(\"[BEST PARAMS]\")\n",
    "print(study.best_params)\n",
    "print(\"Best NDCG@3:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    **study.best_params,\n",
    "    # 'device': 'cuda'\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance = model.get_score(importance_type='gain')\n",
    "xgb_importance_df = pl.DataFrame(\n",
    "    [{'feature': k, 'importance': v} for k, v in xgb_importance.items()]\n",
    ").sort('importance', descending=bool(1))\n",
    "print(xgb_importance_df.to_pandas().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e58a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pl.read_parquet(os.path.join(root_dir, \"kaggle\", \"test.parquet\"))\n",
    "original = (\n",
    "    original\n",
    "    .select([\"Id\", \"ranker_id\"])\n",
    "    .with_columns(\n",
    "        pl.Series(\"score\", pred_scores)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('score')\n",
    "        .rank(method='ordinal', descending=True)\n",
    "        .over('ranker_id')\n",
    "        .alias('selected')\n",
    "    )\n",
    "    .select([\"Id\", \"ranker_id\", \"selected\"])\n",
    "    .with_columns(\n",
    "        pl.col(\"Id\").cast(pl.Int64), \n",
    "        pl.col(\"selected\").cast(pl.Int64)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "original.write_csv(os.path.join(root_dir, \"submission\", f\"submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7ee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
